,s,p,o,source,support,abstracts
0,seals evaluation service,base,web service interface,heuristic,1,['in this deliverable we describe a seals evaluation service for ontology matching that is based on the use of a web service interface to be implemented by the tool vendor . following this approach we can offer an evaluation service before many components of the seals platform have been finished . we describe both the system architecture of the evaluation service from a general point of view as well as the specific components and their relation to the modules of the seals platform .']
1,ontology alignment,base,web service interface,heuristic,1,['in this deliverable we describe a seals evaluation service for ontology matching that is based on the use of a web service interface to be implemented by the tool vendor . following this approach we can offer an evaluation service before many components of the seals platform have been finished . we describe both the system architecture of the evaluation service from a general point of view as well as the specific components and their relation to the modules of the seals platform .']
2,ontology matching approach,base,genetic algorithm (ga),heuristic,1,"['in this paper , we propose a new ontology matching approach , omega , based on genetic algorithms applied on the graph structure of ontologies . our approach finds the linguistic-structural similarities between concepts in two ontologies . it introduces new fitness functions and new criteria for categorizing test cases into four categories . our approach does not need any extra information or resource with exception to the ontology itself . experimental results on applying omega on defined cases show higher performance compared to existing method .']"
3,ontology matching approach,base,graph structure of ontology,heuristic,2,"['in this paper , we propose a new ontology matching approach , omega , based on genetic algorithms applied on the graph structure of ontologies . our approach finds the linguistic-structural similarities between concepts in two ontologies . it introduces new fitness functions and new criteria for categorizing test cases into four categories . our approach does not need any extra information or resource with exception to the ontology itself . experimental results on applying omega on defined cases show higher performance compared to existing method .']"
4,genetic algorithm (ga),uses,graph structure of ontology,heuristic,1,"['in this paper , we propose a new ontology matching approach , omega , based on genetic algorithms applied on the graph structure of ontologies . our approach finds the linguistic-structural similarities between concepts in two ontologies . it introduces new fitness functions and new criteria for categorizing test cases into four categories . our approach does not need any extra information or resource with exception to the ontology itself . experimental results on applying omega on defined cases show higher performance compared to existing method .']"
5,automated ontology matching methodology,supports,machine learning technique,heuristic,2,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
6,machine learning technique,produces,system moto,heuristic,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
7,automated ontology matching methodology,produces,system moto,heuristic,4,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
8,it,uses,meta - learner,heuristic,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
9,semantic search approach,base,hierarchical interest tree,heuristic,1,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
10,semantic search approach,proposes,unstructured p2p systems.document,heuristic,2,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
11,hierarchical interest tree,proposes,unstructured p2p systems.document,heuristic,1,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
12,ordinaryweb user,is,distributed database,heuristic,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
13,semantic search technology,acquires,user information need,heuristic,4,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
14,koio,supports,keyword - based search,heuristic,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
15,koio,supports,structured environmental data,heuristic,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
16,prototype system,represents,semantic search technique,heuristic,2,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
17,internet,produces,digital contents,heuristic,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
18,internet,produces,knowledge retrieval,heuristic,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
19,annotating digital and non - digital content,proposes,descriptive structured and unstructured metadata,heuristic,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
20,mpeg-7,defines,semantic relationships,heuristic,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
21,mpeg group,provides,mpeg-7,heuristic,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
22,mpeg-7,defines,retrieval of the annotation,heuristic,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
23,mpeg group,provides,semantic relationships,heuristic,2,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
24,mpeg group,provides,retrieval of the annotation,heuristic,2,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
25,concept,matches,k- high frequency term,heuristic,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
26,ontologies,matches,k- high frequency term,heuristic,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
27,concept similarity,analyzes,semantic distance,heuristic,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
28,concept similarity,analyzes,concept relevance overlay,heuristic,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
29,ontology based p2p content semantic search routing algorithm,represents,simple flooding,heuristic,2,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
30,metametadata taxonomy,produces,semantic search engines,heuristic,2,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
31,ontologies,learns,learning objects,heuristic,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
32,ontological view,selects,metametadata taxonomy,heuristic,5,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
33,ontological view,learns,control vocabulary,heuristic,4,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
34,control vocabulary,selects,metametadata taxonomy,heuristic,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
35,metametadata,base,metametadata taxonomy,heuristic,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
36,ontological approach,base,metametadata taxonomy,heuristic,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
37,metametadata taxonomy,contributes,semantic searching mechanism,heuristic,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
38,metametadata,contributes,semantic searching mechanism,heuristic,3,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
39,ontological approach,contributes,semantic searching mechanism,heuristic,2,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
40,ontological view,uses,semantic search engines,heuristic,2,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
41,search algorithm,uses,metadata repository,heuristic,2,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
42,search algorithm,uses,semantic search engines,heuristic,2,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
43,it,is,heterogeneous information resource,heuristic,1,"['search is probably the most frequent activity on the web . yet , it is not effortless , mainly due to heterogeneous information resources . semantic search is a means to tackle the problem of ambiguity . in this paper , we analyse a process of constructing semantic-linguistic feature vectors ( fvs ) used in our semantic search approach . these fvs are built based on domain semantics encoded in an ontology and enhanced by relevant terminology from web documents . since fvs are central building blocks of the approach , we investigate the quality of fvs . we take a closer look at the process of fv construction and the impact of chosen techniques on the quality of fvs . we report on a set of laboratory experiments and analyse aspects affecting the fv quality and the fv construction error rates .']"
44,domain semantic,converts,web document,heuristic,2,"['search is probably the most frequent activity on the web . yet , it is not effortless , mainly due to heterogeneous information resources . semantic search is a means to tackle the problem of ambiguity . in this paper , we analyse a process of constructing semantic-linguistic feature vectors ( fvs ) used in our semantic search approach . these fvs are built based on domain semantics encoded in an ontology and enhanced by relevant terminology from web documents . since fvs are central building blocks of the approach , we investigate the quality of fvs . we take a closer look at the process of fv construction and the impact of chosen techniques on the quality of fvs . we report on a set of laboratory experiments and analyse aspects affecting the fv quality and the fv construction error rates .']"
45,ontologies,improves,web document,heuristic,1,"['search is probably the most frequent activity on the web . yet , it is not effortless , mainly due to heterogeneous information resources . semantic search is a means to tackle the problem of ambiguity . in this paper , we analyse a process of constructing semantic-linguistic feature vectors ( fvs ) used in our semantic search approach . these fvs are built based on domain semantics encoded in an ontology and enhanced by relevant terminology from web documents . since fvs are central building blocks of the approach , we investigate the quality of fvs . we take a closer look at the process of fv construction and the impact of chosen techniques on the quality of fvs . we report on a set of laboratory experiments and analyse aspects affecting the fv quality and the fv construction error rates .']"
46,domain semantic,converts,ontologies,heuristic,1,"['search is probably the most frequent activity on the web . yet , it is not effortless , mainly due to heterogeneous information resources . semantic search is a means to tackle the problem of ambiguity . in this paper , we analyse a process of constructing semantic-linguistic feature vectors ( fvs ) used in our semantic search approach . these fvs are built based on domain semantics encoded in an ontology and enhanced by relevant terminology from web documents . since fvs are central building blocks of the approach , we investigate the quality of fvs . we take a closer look at the process of fv construction and the impact of chosen techniques on the quality of fvs . we report on a set of laboratory experiments and analyse aspects affecting the fv quality and the fv construction error rates .']"
47,keyword - based search,converts,semantic search engines,heuristic,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
48,internet search,converts,semantic search engines,heuristic,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
49,annotation data,produces,system,heuristic,3,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
50,video,uses,similarity measure,heuristic,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
51,image,uses,similarity measure,heuristic,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
52,semantic search of cultural content,is,cultural digital library,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
53,cultural digital library,improves,digital public library of america,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
54,semantic search of cultural content,improves,digital public library of america,heuristic,2,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
55,semantic search of cultural content,is,europeana,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
56,europeana,improves,digital public library of america,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
57,automatic visual analysi,is,component-based software engineering,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
58,multimedia,is,component-based software engineering,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
59,semantic search methodology,includes,query answering mechanism,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
60,semantic,improves,local ( surf ),heuristic,2,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
61,query answering mechanism,uses,local ( surf ),heuristic,3,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
62,semantic,improves,global ( mpeg-7 ) visual feature,heuristic,2,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
63,europeana digital library,uses,visual analysis of cultural image,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
64,europeana digital library,uses,thematic knowledge,heuristic,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
65,inference engine,uses,owl language,heuristic,2,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
66,owl language,recommends,language standardization,heuristic,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
67,owl language,recommends,w3c,heuristic,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
68,inference engine,recommends,language standardization,heuristic,3,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
69,inference engine,recommends,w3c,heuristic,3,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
70,inference engine,supports,code verification.the concept architecture,heuristic,3,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
71,inference engine,supports,knowledge bases,heuristic,2,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
72,concept architecture,uses,semantic search engines,heuristic,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
73,semantic search engines,is,concept architecture,heuristic,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
74,knowledge bases,limits,concept architecture,heuristic,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
75,knowledge bases,limits,code verification.the concept architecture,heuristic,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
76,ontologies,improves,day retrieval quality,heuristic,1,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
77,ontologies,improves,semantic founding,heuristic,1,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
78,ontologies,produces,universities,heuristic,3,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
79,retrieval quality,supports,semantic model,heuristic,2,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
80,it,provides,retrieval quality,heuristic,2,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
81,search engines,provides,retrieval quality,heuristic,2,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
82,it,produces,semantic model,heuristic,4,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
83,it,is,search engines,heuristic,1,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
84,semantic service registration,base,wordnet,heuristic,1,"['a method for semantic service registration and query based on wordnet is disclosed . the method includes the following steps : ( 1 ) semantic service registration : a service provider registers a service and uploads the web service description language ( wsdl ) document corresponding to the service , and a system parses the wsdl document to form a service description tree , then constructs a wordnet ontology tree according to the input of the service , performs a semantic annotation on the input/output of the service to form a web service semantic description document ( wsdl-s ) , and finally stores it in a register library ; ( 2 ) semantic service discovery : a service requester inputs the information of service type , semantic information of the service input/output and other user-defined information to the register library to retrieve the services meeting the requirements ; and ( 3 ) similarity sorting : the services meeting a certain threshold are sorted in descending order . the method has the advantages of the combination of wordnet ontology library and the semantic description language of wsdl-s , and definite semantic meaning .']"
85,resource description framework (rdf),proposes,semantic web technologies,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
86,metadata,acquires,xml,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
87,metadata,is,rdf triple,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
88,web,acquires,xml,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
89,web,is,rdf triple,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
90,rdf triple,acquires,xml,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
91,rdf framework,proposes,uniform resource identifier,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
92,rdf framework,proposes,literal,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
93,schema,recommends,w3c,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
94,rdf / xml,recommends,w3c,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
95,rdf / xml,uses,schema,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
96,editor,produces,graphic environment,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
97,editor,produces,html code,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
98,editor,extends,media encoding change,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
99,search engines,selects,keyword,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
100,portal,selects,keyword,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
101,portal,includes,filtering time,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
102,search engines,selects,category,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
103,portal,selects,category,heuristic,2,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
104,portal,includes,search engines,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
105,extra weight,provides,html,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
106,retrieval of article,uses,keyword,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
107,query processing word,provides,information retrieval,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
108,keyword,queries,search engines,heuristic,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
109,middleware,proposes,semantic service discovery and matching approach,heuristic,1,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
110,middleware,matches,service combination proces,heuristic,2,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
111,semantic service discovery and matching approach,analyzes,semantic similarity measures,heuristic,1,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
112,semantic service discovery and matching approach,analyzes,heuristic algorithm,heuristic,1,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
113,service combination proces,analyzes,semantic similarity measures,heuristic,1,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
114,service combination proces,analyzes,heuristic algorithm,heuristic,1,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
115,design,proposes,virtual urban fire fighting,heuristic,1,"['with the development of machine-to-machine ( m2m ) technology , a variety of embedded and mobile devices is integrated to interact via the platform of the internet of things , especially in the domain of smart cities . one of the primary challenges is that selecting the appropriate services or service combination for upper layer applications is hard , which is due to the absence of a unified semantical service description pattern , as well as the service selection mechanism . in this paper , we define a semantic service representation model from four key properties : capability ( c ) , deployment ( d ) , resource ( r ) and iodata ( io ) . based on this model , an agent-based middleware is built to support semantic service enablement . in this middleware , we present an efficient semantic service discovery and matching approach for a service combination process , which calculates the semantic similarity between services , and a heuristic algorithm to search the service candidates for a specific service request . based on this design , we propose a simulation of virtual urban fire fighting , and the experimental results manifest the feasibility and efficiency of our design .']"
116,architecture,represents,execution scenario,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
117,architecture,represents,dynamic test case generation,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
118,validation,represents,execution scenario,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
119,validation,represents,dynamic test case generation,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
120,technological boundary,uses,internet of things ( iot ),heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
121,iot environment,requires,automated interpretation of environmental and context information,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
122,inte- grating service oriented computing mechanism,produces,internet of things (iot),heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
123,semantic web technologies,produces,internet of things (iot),heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
124,inte- grating service oriented computing mechanism,produces,semantic service layer,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
125,semantic web technologies,produces,semantic service layer,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
126,semantic,supports,automated testing,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
127,automated testing,produces,deployed service,heuristic,2,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
128,automated testing,limits,context - aware service adaptation,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
129,semantic,supports,iot service,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
130,semantic,limits,context - aware service adaptation,heuristic,2,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
131,iot service,produces,deployed service,heuristic,2,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
132,context - aware service adaptation,produces,deployed service,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
133,iot service,limits,context - aware service adaptation,heuristic,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
134,formal concept analysi,uses,software engineering,heuristic,2,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
135,formal concept analysi,uses,ai need,heuristic,2,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
136,ontologies,requires,ontology construction,heuristic,2,"['creating and designing an ontology is a complex task requiring discussions between domain and ontology engineering experts as well as the users of an ontology . we present the cicero tool , that facilitates efficient discussions and accelerates the convergence to decisions . furthermore , by integrating it with an ontology editor , it helps to improve the documentation of an ontology .']"
137,similarity measure,is,weight - based similarity aggregation,heuristic,1,"['the basic idea behind the ontology is to conceptualize information that is published in electronic format . the problem of ontology alignment is defined as identifying the relationship shared by the set of different entities where each entity belongs to separate ontology . the amount of similarity between two entities from two different ontologies takes part into the ontology alignment process . there are several similarity measuring methods available in the existing literature for measuring the similarity between two discrete entities from different ontologies . to obtain a comprehensive and precise result , all the similarity measures are integrated . one of the ways to combine the various similarity measures is weight-based similarity aggregation . usually the weights with respect to various similarity measures are assigned manually or through some method . but most of the existing techniques suffer from lack of optimality . also many evolutionary based approaches are available to find the optimal solution for weight-based similarity aggregation but they are designed as single objective optimization problem . this fact has inspired us to develop a multiobjective particle swarm based optimization algorithm for generating optimal weight based similarity aggregation to get a optimal alignment . in this article , two objectives precision and recall are simultaneously optimized . moreover a local search is conducted for replacing the worst population in the new generation by best population acquired from the history . the proposed study is evaluated using an artificial data set and performance of the proposed method is compared with that of its single objective versions .']"
138,evolutionary based approach,selects,weight - based similarity aggregation,heuristic,2,"['the basic idea behind the ontology is to conceptualize information that is published in electronic format . the problem of ontology alignment is defined as identifying the relationship shared by the set of different entities where each entity belongs to separate ontology . the amount of similarity between two entities from two different ontologies takes part into the ontology alignment process . there are several similarity measuring methods available in the existing literature for measuring the similarity between two discrete entities from different ontologies . to obtain a comprehensive and precise result , all the similarity measures are integrated . one of the ways to combine the various similarity measures is weight-based similarity aggregation . usually the weights with respect to various similarity measures are assigned manually or through some method . but most of the existing techniques suffer from lack of optimality . also many evolutionary based approaches are available to find the optimal solution for weight-based similarity aggregation but they are designed as single objective optimization problem . this fact has inspired us to develop a multiobjective particle swarm based optimization algorithm for generating optimal weight based similarity aggregation to get a optimal alignment . in this article , two objectives precision and recall are simultaneously optimized . moreover a local search is conducted for replacing the worst population in the new generation by best population acquired from the history . the proposed study is evaluated using an artificial data set and performance of the proposed method is compared with that of its single objective versions .']"
139,multiobjective particle swarm based optimization algorithm,produces,optimal weight based similarity aggregation,heuristic,1,"['the basic idea behind the ontology is to conceptualize information that is published in electronic format . the problem of ontology alignment is defined as identifying the relationship shared by the set of different entities where each entity belongs to separate ontology . the amount of similarity between two entities from two different ontologies takes part into the ontology alignment process . there are several similarity measuring methods available in the existing literature for measuring the similarity between two discrete entities from different ontologies . to obtain a comprehensive and precise result , all the similarity measures are integrated . one of the ways to combine the various similarity measures is weight-based similarity aggregation . usually the weights with respect to various similarity measures are assigned manually or through some method . but most of the existing techniques suffer from lack of optimality . also many evolutionary based approaches are available to find the optimal solution for weight-based similarity aggregation but they are designed as single objective optimization problem . this fact has inspired us to develop a multiobjective particle swarm based optimization algorithm for generating optimal weight based similarity aggregation to get a optimal alignment . in this article , two objectives precision and recall are simultaneously optimized . moreover a local search is conducted for replacing the worst population in the new generation by best population acquired from the history . the proposed study is evaluated using an artificial data set and performance of the proposed method is compared with that of its single objective versions .']"
140,dialogs of agent,uses,ontologies,heuristic,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
141,poam,uses,syntactical and linguistic technique,heuristic,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
142,concept,base,similarity of their property,heuristic,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
143,"syntactical , structural and semantic one",analyzes,similarity between the property,heuristic,2,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
144,dialog of agent,uses,ontology alignment evaluation initiative,heuristic,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
145,poam,matches,dialog of agent,heuristic,2,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
146,dialog of agent,uses,ontologies,heuristic,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
147,poam,includes,precision,heuristic,2,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
148,poam,includes,recall metric,heuristic,2,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
149,chemical semantic web,uses,machine - processed data,heuristic,1,['we present an overview of the current state of public semantic chemistry and propose new approaches at a strategic and a detailed level . we show by example how a model for a chemical semantic web can be constructed using machine-processed data and information from journal articles .']
150,rsm,supports,semantic model,heuristic,4,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
151,semantic interlinking,uses,semantic model,heuristic,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
152,rsm,includes,service output,heuristic,2,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
153,rsm,includes,service logic,heuristic,2,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
154,rsm,includes,service input,heuristic,2,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
155,rsm,includes,concept,heuristic,2,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
156,web ontology language,proposes,rsm,heuristic,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
157,gene - centric data,produces,zebrafish biology,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
158,public domain,is,nonstandard format,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
159,zebrafish genomewiki,provides,collective annotation of the zebrafish gene,heuristic,3,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
160,zebrafish genomewiki,is,wiki - based resource,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
161,zebrafish genomewiki,affects,gene - centric information,heuristic,5,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
162,wiki,is,structured wiki,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
163,zebrafish genomewiki,is,structured wiki,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
164,wiki,is,semantic wikis,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
165,zebrafish genomewiki,is,semantic wikis,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
166,semantically linked data structure,is,semantic search engines,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
167,zebrafish genomewiki,produces,semantically linked data structure,heuristic,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
168,zebrafish genomewiki,links,semantic search engines,heuristic,3,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
169,logic of multiple - valued argumentation,uses,schedule management system,heuristic,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
170,automated argument system,base,argument - based recommender system,heuristic,2,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
171,logic of multiple - valued argumentation,uses,argument - based recommender system,heuristic,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
172,automated argument system,base,logic of multiple - valued argumentation,heuristic,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
173,automated argument system,base,it,heuristic,2,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
174,logic of multiple - valued argumentation,uses,it,heuristic,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
175,semantic web tool,supports,networked knowledge acquisition,heuristic,1,"['this paper details the use of semantic web tools for supporting networked knowledge acquisition , search and sharing in large distributed organisations . the demonstration will showcase from a user perspective an application developed to aid knowledge management in large organisations , detailing the problems and technical solutions employed .']"
176,user perspective,produces,knowledge management,heuristic,2,"['this paper details the use of semantic web tools for supporting networked knowledge acquisition , search and sharing in large distributed organisations . the demonstration will showcase from a user perspective an application developed to aid knowledge management in large organisations , detailing the problems and technical solutions employed .']"
177,semantic web technologies,guides,semantic relationships,heuristic,1,"[""this paper focuses on a next generation collaborative infrastructure . new developments in the computer science field , including semantic web , peer-to-peer , or natural language processing , will lead to new forms of collaboration and `` social semantic information spaces '' . these will have great impact on scientific communication .""]"
178,natural language processing systems,guides,semantic relationships,heuristic,1,"[""this paper focuses on a next generation collaborative infrastructure . new developments in the computer science field , including semantic web , peer-to-peer , or natural language processing , will lead to new forms of collaboration and `` social semantic information spaces '' . these will have great impact on scientific communication .""]"
179,arc rdf environment,combines,mashup,heuristic,2,"[""an approach towards formalizing the visualization of semantic web data is proposed in this paper . existing apis , like the dojo toolkit , the arc rdf environment , dbpedia and google fusion tables are combined in order to develop a `` mashup '' related to information and knowledge about the mediterranean sea .""]"
180,dojo toolkit,combines,mashup,heuristic,2,"[""an approach towards formalizing the visualization of semantic web data is proposed in this paper . existing apis , like the dojo toolkit , the arc rdf environment , dbpedia and google fusion tables are combined in order to develop a `` mashup '' related to information and knowledge about the mediterranean sea .""]"
181,ontology automatically.a method,proposes,ontology construction,heuristic,3,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
182,ontology construction,uses,ontology automatically.a method,heuristic,1,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
183,ontology construction,uses,wordnet,heuristic,1,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
184,ontology construction,uses,it,heuristic,1,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
185,manually constructed ontology,produces,ontology automatically.a method,heuristic,2,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
186,manually constructed ontology,produces,wordnet,heuristic,5,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
187,semantic web technologies,produces,ontology automatically.a method,heuristic,4,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
188,ontology automatically.a method,proposes,wordnet,heuristic,3,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
189,it,produces,ontology automatically.a method,heuristic,2,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
190,ontology automatically.a method,proposes,it,heuristic,3,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
191,it,produces,wordnet,heuristic,5,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
192,agent technology,automates,interoperation,heuristic,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
193,agent technology,automates,execution,heuristic,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
194,agent technology,automates,composition,heuristic,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
195,semantic service integration,supports,environmental resource,heuristic,1,['problems of semantic service integration to enable interoperability between an intelligent decision support system of supply networks participants and environmental resources are considered .']
196,semantic search system,base,ontology retrieval technology,heuristic,2,"[""a semantic search system of deep web is designed and implemented based on the approach of ontology retrieval technology aim to deep web characteristics.then , the new system can meet the users ' need to obtain the high valued deep web information .""]"
197,semantic search system,base,deep web characteristics.then,heuristic,2,"[""a semantic search system of deep web is designed and implemented based on the approach of ontology retrieval technology aim to deep web characteristics.then , the new system can meet the users ' need to obtain the high valued deep web information .""]"
198,semantic search engine framework,base,ontologies,heuristic,1,"[""the paper brings forth a semantic search engine framework based on ontology , the technology overcomes traditional search engine 's shortcomings such as poor semantic processing capability and understanding capability because of the adoption of text retrieval and greatly lifts the retrieval efficiency .""]"
199,semantic search engines,uses,internet and cloud computing,heuristic,1,"[""qian xuesen 's noetic science , open giant complex system theories and metasynthetic engineering were discussed.with the development of internet and cloud computing , the research and theories can be applied to build a human-like world 's knowledge system for semantic search engine .""]"
200,internet and cloud computing,produces,semantic search engines,heuristic,1,"[""qian xuesen 's noetic science , open giant complex system theories and metasynthetic engineering were discussed.with the development of internet and cloud computing , the research and theories can be applied to build a human-like world 's knowledge system for semantic search engine .""]"
201,metasynthetic engineering,is,internet and cloud computing,heuristic,1,"[""qian xuesen 's noetic science , open giant complex system theories and metasynthetic engineering were discussed.with the development of internet and cloud computing , the research and theories can be applied to build a human-like world 's knowledge system for semantic search engine .""]"
202,human - like world 's knowledge system,uses,internet and cloud computing,heuristic,1,"[""qian xuesen 's noetic science , open giant complex system theories and metasynthetic engineering were discussed.with the development of internet and cloud computing , the research and theories can be applied to build a human-like world 's knowledge system for semantic search engine .""]"
203,internet and cloud computing,produces,human - like world 's knowledge system,heuristic,1,"[""qian xuesen 's noetic science , open giant complex system theories and metasynthetic engineering were discussed.with the development of internet and cloud computing , the research and theories can be applied to build a human-like world 's knowledge system for semantic search engine .""]"
204,ontologies,improves,small - world effect,heuristic,3,"['according to tim-berners lee , the inventor of the www , a semantic web in which software agents find meanings of terms that describe tasks it performs is the next progression of the web . ontologies as repositories of these machine-interpretable meanings are key to his vision . however , ontologies are distributed and not , and will likely never , be centrally organized . enabling agents to find the right meanings then is an important challenge for realizing the semantic web . as ontologies evolve , they will likely form in clusters exhibiting small-world effects , just like web pages . in th is paper , questions about bring to bear findings from social network analysis to the design of these ontologies are raised . one questions stems from the argument that ontology use over a compet ing technology ( xml ) may occur when mitigating uncertainty is important . a research direction to study social networks for dealing with uncertainty then is posited .']"
205,ontologies,improves,web contents,heuristic,3,"['according to tim-berners lee , the inventor of the www , a semantic web in which software agents find meanings of terms that describe tasks it performs is the next progression of the web . ontologies as repositories of these machine-interpretable meanings are key to his vision . however , ontologies are distributed and not , and will likely never , be centrally organized . enabling agents to find the right meanings then is an important challenge for realizing the semantic web . as ontologies evolve , they will likely form in clusters exhibiting small-world effects , just like web pages . in th is paper , questions about bring to bear findings from social network analysis to the design of these ontologies are raised . one questions stems from the argument that ontology use over a compet ing technology ( xml ) may occur when mitigating uncertainty is important . a research direction to study social networks for dealing with uncertainty then is posited .']"
206,databases and information system,guides,information systems,heuristic,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
207,databases and information system,guides,semantic web technologies,heuristic,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
208,semantic web technologies,uses,knowledge management,heuristic,2,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
209,ontologies,uses,knowledge management,heuristic,2,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
210,semantic web technologies,uses,technology,heuristic,2,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
211,ontologies,uses,technology,heuristic,2,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
212,semantic web technologies,provides,human - oriented web service,heuristic,3,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
213,reasoning algorithms,provides,contextual knowledge,heuristic,1,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
214,semantic web vision,maintains,context - dependency of web knowledge,heuristic,2,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
215,ontologies,produces,semantic web vision,heuristic,2,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
216,full - fledged formal context,produces,web ontology,heuristic,1,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
217,reified context,represents,full - fledged formal context,heuristic,3,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
218,modularity of service product design,proposes,ontology - based service product modeling approach,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
219,service product configuration model,base,modularity of service product design,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
220,modularity of service product design,proposes,feature - based service model,heuristic,2,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
221,service product configuration model,base,ontology - based service product modeling approach,heuristic,2,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
222,jes,proposes,service customization,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
223,ontology language,defines,semantic web rule language,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
224,ontology language,defines,rule language.performed configuration reasoning process,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
225,ontology language,defines,semantic web technologies,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
226,ontology language,defines,semantic web rule languages,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
227,semantic web technologies,defines,semantic web rule language,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
228,rule language.performed configuration reasoning process,proposes,service customization,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
229,semantic web technologies,defines,rule language.performed configuration reasoning process,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
230,mass customization,supports,service product configuration model,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
231,semantic web technologies,defines,semantic web rule languages,heuristic,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
232,search query,lacks,user query,heuristic,3,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
233,search query,base,keyword,heuristic,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
234,search query,lacks,semantic inference,heuristic,3,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
235,keyword,lacks,user query,heuristic,2,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
236,keyword,lacks,semantic inference,heuristic,2,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
237,semantic web vocabulary,supports,semantic enrichment of the search index,heuristic,2,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
238,semantic web vocabulary,supports,semantic,heuristic,2,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
239,named entity extraction,supports,semantic enrichment of the search index,heuristic,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
240,external data source,supports,semantic,heuristic,2,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
241,named entity extraction,supports,semantic,heuristic,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
242,ontologies,supports,semantic,heuristic,2,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
243,it,uses,meta - learner,openie,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
244,editor,produces,html code,openie,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
245,portal,includes,search engines,openie,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
246,semantic web technologies,produces,semantic service layer,openie,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
247,zebrafish genomewiki,is,wiki - based resource,openie,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
248,zebrafish genomewiki,is,structured wiki,openie,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
249,zebrafish genomewiki,is,wiki,openie,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
250,existing api,produces,mashup,openie,1,"[""an approach towards formalizing the visualization of semantic web data is proposed in this paper . existing apis , like the dojo toolkit , the arc rdf environment , dbpedia and google fusion tables are combined in order to develop a `` mashup '' related to information and knowledge about the mediterranean sea .""]"
251,ontology alignment,uses,seals evaluation service,luanyi,1,['in this deliverable we describe a seals evaluation service for ontology matching that is based on the use of a web service interface to be implemented by the tool vendor . following this approach we can offer an evaluation service before many components of the seals platform have been finished . we describe both the system architecture of the evaluation service from a general point of view as well as the specific components and their relation to the modules of the seals platform .']
252,seals evaluation service,uses,web service interface,luanyi,1,['in this deliverable we describe a seals evaluation service for ontology matching that is based on the use of a web service interface to be implemented by the tool vendor . following this approach we can offer an evaluation service before many components of the seals platform have been finished . we describe both the system architecture of the evaluation service from a general point of view as well as the specific components and their relation to the modules of the seals platform .']
253,ontology matching approach,uses,genetic algorithm (ga),luanyi,1,"['in this paper , we propose a new ontology matching approach , omega , based on genetic algorithms applied on the graph structure of ontologies . our approach finds the linguistic-structural similarities between concepts in two ontologies . it introduces new fitness functions and new criteria for categorizing test cases into four categories . our approach does not need any extra information or resource with exception to the ontology itself . experimental results on applying omega on defined cases show higher performance compared to existing method .']"
254,automated ontology matching methodology,uses,machine learning technique,luanyi,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
255,it,uses,meta - learner,luanyi,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
256,mapping,uses,meta - learner,luanyi,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
257,benchmark ontology,evaluates,methodology,luanyi,1,"['an automated ontology matching methodology is presented , supported by various machine learning techniques , as implemented in the system moto . the methodology is two-tiered . on the first stage it uses a meta-learner to elicit certain mappings from those predicted by single matchers induced by a specific base-learner . then , uncertain mappings are recovered passing through a validation process , followed by the aggregation of the individual predictions through linguistic quantifiers . experiments on benchmark ontologies demonstrate the effectiveness of the methodology .']"
258,unstructured p2p systems.document,uses,semantic search approach,luanyi,1,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
259,semantic search approach,uses,hierarchical interest tree,luanyi,1,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
260,unstructured p2p systems.document,uses,hierarchical interest tree,luanyi,1,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
261,unstructured p2p systems.document,uses,unstructured p2p systems.document,luanyi,1,"['an effective semantic search approach based on hierarchical interest tree ( hit ) is proposed in unstructured p2p systems.documents owned by a peer are classified into categories to build a hit , which is sent to a super peer.meanwhile , the inverted document index ( idi ) of top n terms for each category is also sent to a super peer according to their chi-square ( 2 ) statistic values.when a regular peer sends a query and gives a category semantic similarity threshold sim_ th , query messages are forwarded via an effective query routing algorithm and the results are returned by searching hit.it is flexible for each peer since it can set the sim_ th , which can provide a better personal service.the experiments show that hit-based semantic search approach is more accurate and efficient than previous methods .']"
262,structured data,uses,semantic search technology,luanyi,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
263,user information need,uses,semantic search technology,luanyi,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
264,koio,is,keyword - based search,luanyi,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
265,keyword - based search,uses,structured environmental data,luanyi,1,"['with the increasing interest in environmental issues , the amount of publicly available environmental data on the web is continuously growing . despite its importance , the uptake of environmental information by the ordinaryweb users is still very limited due to intransparent access to complex and distributed databases . as a remedy to this problem , in this work , we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs . our proposed system , namely koios , enables a simple , keyword-based search on structured environmental data and built on top of a commercial environmental information system ( eis ) . a prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information .']"
266,digital contents,uses,internet,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
267,mpeg group,uses,mpeg-7,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
268,mpeg-7 based semantic annotation,uses,retrieval proces,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
269,query expansion,is,information retrieval technique,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
270,query expansion,conjunction,regular expression,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
271,regular expression,is,information retrieval technique,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
272,nwcbir,is,prototype implementation,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
273,semantic search engines,uses,nwcbir,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
274,semantic search and retrieval,uses,nwcbir,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
275,semantic search engines,uses,prototype implementation,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
276,semantic search and retrieval,uses,prototype implementation,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
277,index termsmpeg-7,conjunction,semantic search engines,luanyi,1,"['with the growing amount of people using the internet , and creating digital content and information , knowledge retrieval becomes a critical task . ongoing efforts provide frameworks and standards for annotating digital and non-digital content semantically to describe resources more precisely and processable in comparison to simple descriptive structured and unstructured metadata . although the mpeg group provides with mpeg-7 , a useful and well defined theoretical framework for the creation of semantic annotation , retrieval of the annotations is not discussed . in this paper we present a retrieval process for mpeg-7 based semantic annotations founded on well proved information retrieval techniques , namely query expansion and regular expressions . additionally nwcbir , a prototype implementation for semantic search and retrieval will be presented . index termsmpeg-7 , nwcbir , semantic search and retrieval .']"
278,p2p context search,includes,low text semantic relevance degree,luanyi,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
279,concept similarity,uses,semantic distance,luanyi,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
280,semantic peer,uses,search request,luanyi,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
281,semantic relevance resource,uses,search request,luanyi,1,"['aiming at existing deficiencies such as low text semantic relevance degree in p2p context search , an ontology-based p2p content semantic search routing algorithm is developed . in this algorithm , texts are described as ontology and concepts are mapped from k- high frequency term . concept similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers . based on the concept relevance overlay , search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic . finally , the experiment was done to validate the efficiency and validity of ontology based p2p content semantic search routing algorithm , in which the result had shown that the algorithm is much better than simple flooding in semantic relevance degree of text .']"
282,semantic search engines,uses,metametadata taxonomy,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
283,ontological approach,conjunction,metametadata,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
284,semantic searching mechanism,uses,ontological approach,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
285,semantic searching mechanism,uses,metametadata,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
286,semantic searching mechanism,uses,metametadata taxonomy,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
287,taxonomy,conjunction,ontological view,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
288,ontological view,conjunction,search algorithm,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
289,semantic search engines,uses,search algorithm,luanyi,1,"['this paper discusses on a novel method for semantic searching and retrieval of information about learning materials . a novel metametadata taxonomy has been developed which provides the basis for a semantic search engine to extract , match and map queries to retrieve relevant results . metametadata encapsulate metadata instances by using the properties and attributes provided by ontologies rather than describing learning objects . the use of ontological views assists the pedagogical content of metadata extracted from learning objects by using the control vocabularies as identified from the metametadata taxonomy . the use of ontological approach and metametadata ( based on the metametadata taxonomy ) have contributed towards a novel semantic searching mechanism . these three strands - the taxonomy , the ontological views , and the search algorithm - are integrated into an architecture ( omescod ) to support the semantic search within the metadata repository .']"
290,domain semantic,uses,web document,luanyi,1,"['search is probably the most frequent activity on the web . yet , it is not effortless , mainly due to heterogeneous information resources . semantic search is a means to tackle the problem of ambiguity . in this paper , we analyse a process of constructing semantic-linguistic feature vectors ( fvs ) used in our semantic search approach . these fvs are built based on domain semantics encoded in an ontology and enhanced by relevant terminology from web documents . since fvs are central building blocks of the approach , we investigate the quality of fvs . we take a closer look at the process of fv construction and the impact of chosen techniques on the quality of fvs . we report on a set of laboratory experiments and analyse aspects affecting the fv quality and the fv construction error rates .']"
291,fv quality,conjunction,fv construction error rate,luanyi,1,"['search is probably the most frequent activity on the web . yet , it is not effortless , mainly due to heterogeneous information resources . semantic search is a means to tackle the problem of ambiguity . in this paper , we analyse a process of constructing semantic-linguistic feature vectors ( fvs ) used in our semantic search approach . these fvs are built based on domain semantics encoded in an ontology and enhanced by relevant terminology from web documents . since fvs are central building blocks of the approach , we investigate the quality of fvs . we take a closer look at the process of fv construction and the impact of chosen techniques on the quality of fvs . we report on a set of laboratory experiments and analyse aspects affecting the fv quality and the fv construction error rates .']"
292,document,conjunction,image,luanyi,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
293,image,conjunction,video,luanyi,2,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
294,semantic search engines,uses,internet search,luanyi,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
295,semantic search engines,uses,metadata,luanyi,1,"['various documents , images , videos and other materials on the web has been increasing rapidly . efficient search of those things has become an important topic . from keyword-based search , internet search has been transformed to semantic search which finds the implications and the relations between data elements . many annotation processing systems manipulating the metadata for semantic search have been proposed . however , annotation data generated by different methods and forms are difficult to process integrated search between those systems . in this study , in order to resolve this problem , we categorized levels of many annotation documents , and we proposed the method to measure the similarity between the annotation documents . similarity measure between annotation documents can be used for searching similar or related documents , images , and videos regardless of the forms of the source data .']"
296,semantic search of cultural content,is,cultural digital library,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
297,europeana,is,cultural digital library,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
298,digital public library of america,is,cultural digital library,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
299,digitised item,uses,content metadata,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
300,semantic search methodology,includes,query answering mechanism,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
301,local ( surf ),conjunction,global ( mpeg-7 ) visual feature,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
302,global ( mpeg-7 ) visual feature,conjunction,descriptors,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
303,thematic knowledge,conjunction,visual analysis of cultural image,luanyi,1,"[""semantic search of cultural content is of major importance in current cultural digital libraries , such as europeana , or the evolving digital public library of america . content metadata accompanying the digitised items are analysed , mapped and used to interpret users ' queries , so that the most appropriate content is selected and presented to them . multimedia , especially automatic visual analysis , has not been a main component yet . this paper presents a semantic search methodology , including a query answering mechanism which meets the semantics of users ' queries and enriches the answers by exploiting appropriate local ( surf ) and global ( mpeg-7 ) visual features and descriptors . an experimental study is presented , using content from the europeana digital library , involving both thematic knowledge and visual analysis of cultural images , illustrating the improved content search performance . ( 4 pages )""]"
304,semantic search engines,uses,semantic search engines,luanyi,1,"['the future www search engine will not only be used to search text , but also can understand the web content , carry out logical reasoning , and achieve the complex search query and feed back correct results.a concept architecture used for semantic search engine was established.the constructional elements in the concept architecture and their interaction process are discussed in this paper.the superiority of the concept architecture is demonstrated by comparing with traditional semantic search engines.the current problem of the inference engine is that they do not support a sound knowledge base , so its function is limited in the code verification.the concept architecture mentioned in this paper has no such a problem , because the architecture of the inference engine has a complete knowledge base.by using owl language recommended by w3c , the language standardization is achieved .']"
305,day retrieval quality,uses,ontologies,luanyi,1,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
306,information unit,uses,semantic search engines,luanyi,1,"[""ontologies aim to improve present day retrieval quality by means of their semantic founding . we introduce a particular ontology , developed and used by the university of applied sciences darmstadt , which covers the university world both broadly and at the same time at a very detailed level . an appropriate semantic search has to fulfil two different requirements : for the user it should be as simple as any of the well known search engines , and at the same time it has to provide outstanding retrieval quality , making use of its ' underlying semantic model of the world . we describe the relevant features of the software k-infinity and the way we use these features to build a powerful semantic search for documents and other information units ( persons , meetings , projects etc . ) on top of the university world ontology .""]"
307,it,uses,semantic relationships,luanyi,1,"['a method for semantic service registration and query based on wordnet is disclosed . the method includes the following steps : ( 1 ) semantic service registration : a service provider registers a service and uploads the web service description language ( wsdl ) document corresponding to the service , and a system parses the wsdl document to form a service description tree , then constructs a wordnet ontology tree according to the input of the service , performs a semantic annotation on the input/output of the service to form a web service semantic description document ( wsdl-s ) , and finally stores it in a register library ; ( 2 ) semantic service discovery : a service requester inputs the information of service type , semantic information of the service input/output and other user-defined information to the register library to retrieve the services meeting the requirements ; and ( 3 ) similarity sorting : the services meeting a certain threshold are sorted in descending order . the method has the advantages of the combination of wordnet ontology library and the semantic description language of wsdl-s , and definite semantic meaning .']"
308,it,uses,user - defined information,luanyi,1,"['a method for semantic service registration and query based on wordnet is disclosed . the method includes the following steps : ( 1 ) semantic service registration : a service provider registers a service and uploads the web service description language ( wsdl ) document corresponding to the service , and a system parses the wsdl document to form a service description tree , then constructs a wordnet ontology tree according to the input of the service , performs a semantic annotation on the input/output of the service to form a web service semantic description document ( wsdl-s ) , and finally stores it in a register library ; ( 2 ) semantic service discovery : a service requester inputs the information of service type , semantic information of the service input/output and other user-defined information to the register library to retrieve the services meeting the requirements ; and ( 3 ) similarity sorting : the services meeting a certain threshold are sorted in descending order . the method has the advantages of the combination of wordnet ontology library and the semantic description language of wsdl-s , and definite semantic meaning .']"
309,semantic service discovery,uses,user - defined information,luanyi,1,"['a method for semantic service registration and query based on wordnet is disclosed . the method includes the following steps : ( 1 ) semantic service registration : a service provider registers a service and uploads the web service description language ( wsdl ) document corresponding to the service , and a system parses the wsdl document to form a service description tree , then constructs a wordnet ontology tree according to the input of the service , performs a semantic annotation on the input/output of the service to form a web service semantic description document ( wsdl-s ) , and finally stores it in a register library ; ( 2 ) semantic service discovery : a service requester inputs the information of service type , semantic information of the service input/output and other user-defined information to the register library to retrieve the services meeting the requirements ; and ( 3 ) similarity sorting : the services meeting a certain threshold are sorted in descending order . the method has the advantages of the combination of wordnet ontology library and the semantic description language of wsdl-s , and definite semantic meaning .']"
310,wordnet ontology library,conjunction,semantic description language,luanyi,1,"['a method for semantic service registration and query based on wordnet is disclosed . the method includes the following steps : ( 1 ) semantic service registration : a service provider registers a service and uploads the web service description language ( wsdl ) document corresponding to the service , and a system parses the wsdl document to form a service description tree , then constructs a wordnet ontology tree according to the input of the service , performs a semantic annotation on the input/output of the service to form a web service semantic description document ( wsdl-s ) , and finally stores it in a register library ; ( 2 ) semantic service discovery : a service requester inputs the information of service type , semantic information of the service input/output and other user-defined information to the register library to retrieve the services meeting the requirements ; and ( 3 ) similarity sorting : the services meeting a certain threshold are sorted in descending order . the method has the advantages of the combination of wordnet ontology library and the semantic description language of wsdl-s , and definite semantic meaning .']"
311,wsdl - s,conjunction,semantic description language,luanyi,1,"['a method for semantic service registration and query based on wordnet is disclosed . the method includes the following steps : ( 1 ) semantic service registration : a service provider registers a service and uploads the web service description language ( wsdl ) document corresponding to the service , and a system parses the wsdl document to form a service description tree , then constructs a wordnet ontology tree according to the input of the service , performs a semantic annotation on the input/output of the service to form a web service semantic description document ( wsdl-s ) , and finally stores it in a register library ; ( 2 ) semantic service discovery : a service requester inputs the information of service type , semantic information of the service input/output and other user-defined information to the register library to retrieve the services meeting the requirements ; and ( 3 ) similarity sorting : the services meeting a certain threshold are sorted in descending order . the method has the advantages of the combination of wordnet ontology library and the semantic description language of wsdl-s , and definite semantic meaning .']"
312,rdf framework,uses,uniform resource identifier,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
313,rdf / xml,uses,schema,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
314,w3c,conjunction,schema,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
315,w3c,conjunction,dcmi,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
316,w3c,conjunction,prism,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
317,dcmi,conjunction,prism,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
318,html code,uses,editor,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
319,html code,uses,graphic environment,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
320,portal,includes,search engines,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
321,filtering time,conjunction,category,luanyi,1,"[""the resource description framework ( rdf ) is an appropriate framework for describing resources as metadata in the semantic web . the aim of semantic # r # # n # web is the development and expansion of the existing web , so users can acquire more integrated the supplied information . today 's web is human oriented . in order to # r # # n # facilitate complex queries and the combination of the acquired data , web is changing orientation . to relieve the user from the extra burden the semantic web shall be interpreted by machines . the most ambitious form incorporating appropriate metadata on the web is by the description of data with rdf triples stored as xml . the rdf framework describes resources , with the use of uniform resource identifiers ( uri 's ) or literals as subject-predicate-object . the use of existing rdf vocabularies to describe classes and properties is encouraged by the w3c. # r # # n # in this work an information-news rdf portal has been developed . the rdf / xml , is created using vocabularies and schemas recommended by w3c and the well known dcmi and prism . the metadata is created automatically with the use of data supplied when a new articles is published . to facilitate the journalist job , a rich text editor , which enables formatting text and inserting images and media has been used and expanded . the editor automatically generates html code from text in a graphic environment . the capabilities of the editor were extended in order to support images and media uploading and media encoding changes for better compatibility with the standards of html5 . apart from uploading articles with the use of the editor the portal integrates articles published by external sources . the process is totally # r # # n # automatic and repetitive . the user of the portal is presented a front page and articles categorized by theme . the portal includes a search engine , with fields for filtering time , category , journalist-source and keywords . the keywords can be supplied by the publisher or selected automatically . when the articles are integrated from external sources , the process is necessarily automatic . for the automatic selection of the keywords the frequency of each word in the article is used . extra weight is given by the html for the words stressed ( e.g . title , bold , underlined ) , normalized for the size of the article and stem frequency of the word in a set of articles that were already uploaded . for the retrieval of articles by the search engine the portal is using an index as inverted files for all keywords . to reduce the data volume and accelerate # r # # n # the query processing words that have high frequency and low value information retrieval `` stop words '' are removed . the choice of a representative list of stop words is performed by using a corpus of newspaper articles , measuring the frequency of words and comparing them with the list of stop words of google . to further reduce # r # # n # the volume of data and increase the recall to questions , the portal stems the keywords . for the stemming the rule based algorithm presented in the thesis of george ntais in the university of stockholm -based grammar was used . the returned articles # r # # n # to the keywords queried by the search engine are ranked by the proximity # r # # n # of the keywords the article is indexed . to enhance the search engine synonymous words are also included by the portal .""]"
322,dynamic test case generation,conjunction,execution scenario,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
323,mobility of resource,conjunction,dynamicity of the environment,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
324,inte- grating service oriented computing mechanism,conjunction,semantic web technologies,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
325,semantic service layer,uses,inte- grating service oriented computing mechanism,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
326,semantic service layer,uses,semantic web technologies,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
327,internet of things (iot),includes,semantic service layer,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
328,automated testing,uses,semantic,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
329,deployed service,uses,context - aware service adaptation,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
330,service creation and testing,uses,architecture,luanyi,1,"['the information generated from the internet of things ( iot ) poten- tially enables a better understanding of the physical world for humans and supports creation of ambient intelligence for a wide range of applications in dif- ferent domains . a semantics-enabled service layer is a promising approach to facilitate seamless access and management of the information from the large , distributed and heterogeneous sources . this paper presents the efforts of the iot.est project towards developing a framework for service creation and testing in an iot environment . the architecture design extends the existing iot refer- ence architecture and enables a test-driven , semantics-based management of the entire service lifecycle . the validation of the architecture is shown though a dynamic test case generation and execution scenario . a dynamic service creation environment ( sce ) that gathers and exploits data and information from the heterogeneous sources can help to overcome the technological boundaries and dynamically design and integrate new services and business opportun- ities for the internet of things ( iot ) . rapid service creation and deployment in iot environments requires a large number of resources and automated interpretation of environmental and context information . moreover , the mobility of resources and the dynamicity of the environment necessitate integration of test-friendly description capabilities in the development and maintenance of services from the beginning . inte- grating service oriented computing mechanisms and semantic technologies to create a semantic service layer on the top of iot is a promising approach for facilitating seam- less access and management of the information from the large , distributed and hetero- geneous sources . the application of semantics to enable automated testing of the iot services can reduce the time to deployment , while context-aware service adaptation can support deployed services to respond to environmental changes . in this paper , we present an architecture for service creation and testing in an iot environment , which']"
331,software engineering,is,ai need,luanyi,1,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
332,software engineering,conjunction,knowledge processing,luanyi,1,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
333,knowledge processing,is,ai need,luanyi,1,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
334,knowledge processing,conjunction,ontology construction,luanyi,1,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
335,ontology construction,is,ai need,luanyi,1,"['formal concept analysis ( fca ) is well-founded mathematical theory which has been widely used for many ai needs such as software engineering , knowledge processing , ontology engineering etc . this is a survey paper in which we analyze recent literature on fca and some closely related applications using fca . finally , the new trends and future perspectives are discussed .']"
336,ontologies,uses,it,luanyi,1,"['creating and designing an ontology is a complex task requiring discussions between domain and ontology engineering experts as well as the users of an ontology . we present the cicero tool , that facilitates efficient discussions and accelerates the convergence to decisions . furthermore , by integrating it with an ontology editor , it helps to improve the documentation of an ontology .']"
337,weight - based similarity aggregation,uses,evolutionary based approach,luanyi,1,"['the basic idea behind the ontology is to conceptualize information that is published in electronic format . the problem of ontology alignment is defined as identifying the relationship shared by the set of different entities where each entity belongs to separate ontology . the amount of similarity between two entities from two different ontologies takes part into the ontology alignment process . there are several similarity measuring methods available in the existing literature for measuring the similarity between two discrete entities from different ontologies . to obtain a comprehensive and precise result , all the similarity measures are integrated . one of the ways to combine the various similarity measures is weight-based similarity aggregation . usually the weights with respect to various similarity measures are assigned manually or through some method . but most of the existing techniques suffer from lack of optimality . also many evolutionary based approaches are available to find the optimal solution for weight-based similarity aggregation but they are designed as single objective optimization problem . this fact has inspired us to develop a multiobjective particle swarm based optimization algorithm for generating optimal weight based similarity aggregation to get a optimal alignment . in this article , two objectives precision and recall are simultaneously optimized . moreover a local search is conducted for replacing the worst population in the new generation by best population acquired from the history . the proposed study is evaluated using an artificial data set and performance of the proposed method is compared with that of its single objective versions .']"
338,optimal weight based similarity aggregation,uses,multiobjective particle swarm based optimization algorithm,luanyi,1,"['the basic idea behind the ontology is to conceptualize information that is published in electronic format . the problem of ontology alignment is defined as identifying the relationship shared by the set of different entities where each entity belongs to separate ontology . the amount of similarity between two entities from two different ontologies takes part into the ontology alignment process . there are several similarity measuring methods available in the existing literature for measuring the similarity between two discrete entities from different ontologies . to obtain a comprehensive and precise result , all the similarity measures are integrated . one of the ways to combine the various similarity measures is weight-based similarity aggregation . usually the weights with respect to various similarity measures are assigned manually or through some method . but most of the existing techniques suffer from lack of optimality . also many evolutionary based approaches are available to find the optimal solution for weight-based similarity aggregation but they are designed as single objective optimization problem . this fact has inspired us to develop a multiobjective particle swarm based optimization algorithm for generating optimal weight based similarity aggregation to get a optimal alignment . in this article , two objectives precision and recall are simultaneously optimized . moreover a local search is conducted for replacing the worst population in the new generation by best population acquired from the history . the proposed study is evaluated using an artificial data set and performance of the proposed method is compared with that of its single objective versions .']"
339,objectives precision,conjunction,recall,luanyi,1,"['the basic idea behind the ontology is to conceptualize information that is published in electronic format . the problem of ontology alignment is defined as identifying the relationship shared by the set of different entities where each entity belongs to separate ontology . the amount of similarity between two entities from two different ontologies takes part into the ontology alignment process . there are several similarity measuring methods available in the existing literature for measuring the similarity between two discrete entities from different ontologies . to obtain a comprehensive and precise result , all the similarity measures are integrated . one of the ways to combine the various similarity measures is weight-based similarity aggregation . usually the weights with respect to various similarity measures are assigned manually or through some method . but most of the existing techniques suffer from lack of optimality . also many evolutionary based approaches are available to find the optimal solution for weight-based similarity aggregation but they are designed as single objective optimization problem . this fact has inspired us to develop a multiobjective particle swarm based optimization algorithm for generating optimal weight based similarity aggregation to get a optimal alignment . in this article , two objectives precision and recall are simultaneously optimized . moreover a local search is conducted for replacing the worst population in the new generation by best population acquired from the history . the proposed study is evaluated using an artificial data set and performance of the proposed method is compared with that of its single objective versions .']"
340,dialog of agent,uses,poam,luanyi,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
341,dialog of agent,uses,ontologies,luanyi,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
342,precision,conjunction,recall metric,luanyi,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
343,recall metric,evaluates,poam,luanyi,1,"[""this paper describes a method to partially align ontologies in dialogs of agents which use different ontologies . the method aims at aligning in execution time only the concepts necessary to the agents fulfill the current dialog . thus , reducing the number of concepts to be searched in the target ontology is a very important requirement for agents ' mutual understanding . the proposed method ( named poam , acronym for partial ontology alignment method ) uses syntactical and linguistic techniques to group concepts together . the underlying rationale of poam is that a person perceives an object and immediately identifies some properties . even never before seen objects can be interpreted independently of any class , because properties in the real world exist independently of any class . hence , similarity between a pair of concepts is calculated based on the similarity of their properties . a set of measures including syntactical , structural and semantic ones are used to calculate similarity between the properties associated to the concepts . a property signature vector is created for each concept and the similarity between two concepts is given by the distance between the corresponding vectors in a high dimensional space . we demonstrate that poam reduces the number of candidate mappings when aligning concepts in a dialog of agents by means of an evaluation using ontologies from the bibliographic domain of the ontology alignment evaluation initiative ( oaei ) . we also show that poam performs satisfactorily well considering the quality of results measured with the precision and recall metrics .""]"
344,resource description framework permitira,conjunction,num futuro bem proximo,luanyi,1,"['este trabalho examina como o modelo conceitual functional requirements for bibliographic records se aproxima da nocao de unidade documentaria atribuida a paul otlet e presente no traite de documentation , cujos principios sao aplicados ao fundamentar as bases do repertorio bibliografico universal . em termos teoricos e metodologicos , trata-se de pesquisa exploratoria de carater historico e documental , cujo objetivo e averiguar os pressupostos classicos da representacao e organizacao da informacao , relacionando-os com o contexto da web semntica . avanca analisando os resultados de simulacoes acerca da aplicacao dos functional requirements for bibliographic records no repositorio acesso livre a informacao cientifica da empresa brasileira de pesquisa agropecuaria , de modo a ilustrar como as teses de otlet se aplicam a essas ferramentas bibliograficas . mostra as vantagens dos repositorios nos processos de modelagem , pois o formato dublin core permite a descricao de metadados usando linguagens como a resource description framework , o que potencializa a recuperacao de informacoes . finaliza demonstrando como os principios - monografico , da continuidade e da pluralidade - , se expressam nas entidades do grupo i do modelo conceitual functional requirements for bibliographic records , o que revela as afinidades metodologicas entre o modelo e as teses de otlet . ressalta que acoes direcionadas no sentido de incentivar a descricao dos metadados bibliograficos em declaracoes em resource description framework permitira , num futuro bem proximo , que cada recurso seja identificado de forma pertinente por meio de um identificador universal - uniform resource identifier - , possibilitando que os registros das bases de dados sejam interligados , permitindo ao usuario acesso a uma massa informacional ha seculos estocada , tal como preconizou otlet ao criar o repertorio bibliografico universal .']"
345,num futuro bem proximo,is,uniform resource identifier,luanyi,1,"['este trabalho examina como o modelo conceitual functional requirements for bibliographic records se aproxima da nocao de unidade documentaria atribuida a paul otlet e presente no traite de documentation , cujos principios sao aplicados ao fundamentar as bases do repertorio bibliografico universal . em termos teoricos e metodologicos , trata-se de pesquisa exploratoria de carater historico e documental , cujo objetivo e averiguar os pressupostos classicos da representacao e organizacao da informacao , relacionando-os com o contexto da web semntica . avanca analisando os resultados de simulacoes acerca da aplicacao dos functional requirements for bibliographic records no repositorio acesso livre a informacao cientifica da empresa brasileira de pesquisa agropecuaria , de modo a ilustrar como as teses de otlet se aplicam a essas ferramentas bibliograficas . mostra as vantagens dos repositorios nos processos de modelagem , pois o formato dublin core permite a descricao de metadados usando linguagens como a resource description framework , o que potencializa a recuperacao de informacoes . finaliza demonstrando como os principios - monografico , da continuidade e da pluralidade - , se expressam nas entidades do grupo i do modelo conceitual functional requirements for bibliographic records , o que revela as afinidades metodologicas entre o modelo e as teses de otlet . ressalta que acoes direcionadas no sentido de incentivar a descricao dos metadados bibliograficos em declaracoes em resource description framework permitira , num futuro bem proximo , que cada recurso seja identificado de forma pertinente por meio de um identificador universal - uniform resource identifier - , possibilitando que os registros das bases de dados sejam interligados , permitindo ao usuario acesso a uma massa informacional ha seculos estocada , tal como preconizou otlet ao criar o repertorio bibliografico universal .']"
346,napster,conjunction,gnutella,luanyi,1,['napster and gnutella are applications that imprinted the term peer-to-peer to the mind of most web users around the world . in this article we will discuss the possibilities of use of this technology in touch with another branch of the computer science -- the semantic web .']
347,computer science,includes,semantic web technologies,luanyi,1,['napster and gnutella are applications that imprinted the term peer-to-peer to the mind of most web users around the world . in this article we will discuss the possibilities of use of this technology in touch with another branch of the computer science -- the semantic web .']
348,chemical semantic web,uses,machine - processed data,luanyi,1,['we present an overview of the current state of public semantic chemistry and propose new approaches at a strategic and a detailed level . we show by example how a model for a chemical semantic web can be constructed using machine-processed data and information from journal articles .']
349,semantic service framework,is,phenomenically contradictory service annotation paradigm,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
350,semantic interlinking,uses,rsm,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
351,rsm,uses,semantic model,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
352,semantic interlinking,uses,semantic model,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
353,rsm,uses,design science research methodology,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
354,semantic service model,conjunction,soa service model,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
355,service input,conjunction,service output,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
356,service input,conjunction,service logic,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
357,service input,conjunction,service provider,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
358,service input,conjunction,service client,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
359,service output,conjunction,service logic,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
360,service output,conjunction,service provider,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
361,service output,conjunction,service client,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
362,service output,conjunction,service feedback,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
363,service logic,conjunction,service feedback,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
364,service provider,conjunction,service feedback,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
365,service client,conjunction,service feedback,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
366,semantic service model,uses,rsm,luanyi,1,"['this paper introduces a reference service model ( rsm ) that closes the gap between two phenomenically contradictory service annotation paradigms : traditional semantic service frameworks and the emerging social annotation of services . rsm aims to ( i ) facilitate the semantic interlinking between services annotated using different semantic models and ( ii ) accommodate the bottom-up social annotation of services . rsm was developed following the design science research methodology . to develop rsm , existing semantic service models and soa service models were reviewed in the light of the six service contracts and examined whether and using which elements each of the models supports in each of the contracts . the identified elements were then fed to a multiphase abstraction exercise . rsm comprises of the following concepts : service , service input , service output , service context and service logic , service provider , service client and service feedback . the paper also maps the concepts of rsm to those of existing semantic service models and positions rsm with respect to related soa service models . finally , an implementation of rsm in owl and two pilot developments that highlight different aspects of rsm are discussed .']"
367,database intercommunication,uses,open standard,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
368,zebrafish gene annotation,uses,community - centric solution,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
369,zebrafish genomewiki,is,wiki - based resource,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
370,zebrafish genomewiki,is,structured wiki,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
371,zebrafish genomewiki,is,semantic wikis,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
372,zebrafish genomewiki,uses,structured wiki,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
373,structured wiki,conjunction,semantic wikis,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
374,semantically linked data structure,uses,zebrafish genomewiki,luanyi,1,"['a large repertoire of gene-centric data has been generated in the field of zebrafish biology . although the bulk of these data are available in the public domain , most of them are not readily accessible or available in nonstandard formats . one major challenge is to unify and integrate these widely scattered data sources . we tested the hypothesis that active community participation could be a viable option to address this challenge . we present here our approach to create standards for assimilation and sharing of information and a system of open standards for database intercommunication . we have attempted to address this challenge by creating a community-centric solution for zebrafish gene annotation . the zebrafish genomewiki is a wiki-based resource , which aims to provide an altruistic shared environment for collective annotation of the zebrafish genes . the zebrafish genomewiki has features that enable users to comment , annotate , edit and rate this gene-centric information . the credits for contributions can be tracked through a transparent microattribution system . in contrast to other wikis , the zebrafish genomewiki is a structured wiki or rather a semantic wiki . the zebrafish genomewiki implements a semantically linked data structure , which in the future would be amenable to semantic search. # r # # n # # r # # n # database url : http : //genome.igib.res.in/twiki']"
375,automated argument system,uses,logic of multiple - valued argumentation,luanyi,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
376,automated argument system,uses,it,luanyi,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
377,semantic web reasoning,conjunction,argument - based reasoning,luanyi,1,"['we demonstrate the basic features and advantages of automated argument system based on logic of multiple-valued argumentation by applying it to three convincing arguments : ( i ) argument-based recommender system , ( ii ) schedule management system and ( iii ) an integrated system of semantic web reasoning and argument-based reasoning .']"
378,networked knowledge acquisition,uses,semantic web tool,luanyi,1,"['this paper details the use of semantic web tools for supporting networked knowledge acquisition , search and sharing in large distributed organisations . the demonstration will showcase from a user perspective an application developed to aid knowledge management in large organisations , detailing the problems and technical solutions employed .']"
379,dojo toolkit,is,existing api,luanyi,1,"[""an approach towards formalizing the visualization of semantic web data is proposed in this paper . existing apis , like the dojo toolkit , the arc rdf environment , dbpedia and google fusion tables are combined in order to develop a `` mashup '' related to information and knowledge about the mediterranean sea .""]"
380,arc rdf environment,is,existing api,luanyi,1,"[""an approach towards formalizing the visualization of semantic web data is proposed in this paper . existing apis , like the dojo toolkit , the arc rdf environment , dbpedia and google fusion tables are combined in order to develop a `` mashup '' related to information and knowledge about the mediterranean sea .""]"
381,ontologies,uses,ontologies,luanyi,2,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...', 'ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
382,ontologies,uses,ontology automatically.a method,luanyi,1,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
383,ontology construction,uses,it,luanyi,1,"['ontology plays a key role in the semantic web , but there exist problems in manually constructed ontology and it is impossible to construct ontology automatically.a method has been proposed for constructing ontology semi-automatically by reusing wordnet , and it can be applied in ontology construction efficiently .']"
384,automated web service discovery,uses,agent technology,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
385,execution,uses,agent technology,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
386,automated web service discovery,conjunction,execution,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
387,automated web service discovery,conjunction,composition,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
388,execution,conjunction,composition,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
389,execution,conjunction,interoperation,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
390,composition,conjunction,interoperation,luanyi,1,"['the authors propose the markup of web services in the daml family of semantic web markup languages . this markup enables a wide variety of agent technologies for automated web service discovery , execution , composition and interoperation . the authors present one such technology for automated web service composition .']"
391,data standard,conjunction,terminology,luanyi,1,"['the aim of this work is to explore the data structures , data standards , terminologies , ontologies , and existing semantic web solutions in electrophysiology and neurophysiology community at the present time . the last part is devoted to the design of the structure and objectives of the dissertation thesis .']"
392,data standard,conjunction,ontologies,luanyi,1,"['the aim of this work is to explore the data structures , data standards , terminologies , ontologies , and existing semantic web solutions in electrophysiology and neurophysiology community at the present time . the last part is devoted to the design of the structure and objectives of the dissertation thesis .']"
393,terminology,conjunction,ontologies,luanyi,1,"['the aim of this work is to explore the data structures , data standards , terminologies , ontologies , and existing semantic web solutions in electrophysiology and neurophysiology community at the present time . the last part is devoted to the design of the structure and objectives of the dissertation thesis .']"
394,ontologies,conjunction,semantic web solution,luanyi,1,"['the aim of this work is to explore the data structures , data standards , terminologies , ontologies , and existing semantic web solutions in electrophysiology and neurophysiology community at the present time . the last part is devoted to the design of the structure and objectives of the dissertation thesis .']"
395,semantic search system,uses,ontology retrieval technology,luanyi,1,"[""a semantic search system of deep web is designed and implemented based on the approach of ontology retrieval technology aim to deep web characteristics.then , the new system can meet the users ' need to obtain the high valued deep web information .""]"
396,semantic search engine framework,uses,ontologies,luanyi,1,"[""the paper brings forth a semantic search engine framework based on ontology , the technology overcomes traditional search engine 's shortcomings such as poor semantic processing capability and understanding capability because of the adoption of text retrieval and greatly lifts the retrieval efficiency .""]"
397,semantic search engines,uses,human - like world 's knowledge system,luanyi,1,"[""qian xuesen 's noetic science , open giant complex system theories and metasynthetic engineering were discussed.with the development of internet and cloud computing , the research and theories can be applied to build a human-like world 's knowledge system for semantic search engine .""]"
398,online collaboration platform,uses,semantic web technologies,luanyi,1,"['through a demonstrated attempt to identify and evaluate opportunities offered by semantic technology to online collaboration platforms ( ocps ) , a context-specific requirements engineering process is developed and documented . seven illustrative functionalities are proposed and evaluation of their demand and feasibility has indicated potential challenges such as access to data from other projects , the need for controlled workflows and the utility of standard data models . the approach can be developed to evaluate technical feasibility as well to ultimately characterize the natural contribution of semantic technology to ocps .']"
399,www,is,semantic web technologies,luanyi,1,"['according to tim-berners lee , the inventor of the www , a semantic web in which software agents find meanings of terms that describe tasks it performs is the next progression of the web . ontologies as repositories of these machine-interpretable meanings are key to his vision . however , ontologies are distributed and not , and will likely never , be centrally organized . enabling agents to find the right meanings then is an important challenge for realizing the semantic web . as ontologies evolve , they will likely form in clusters exhibiting small-world effects , just like web pages . in th is paper , questions about bring to bear findings from social network analysis to the design of these ontologies are raised . one questions stems from the argument that ontology use over a compet ing technology ( xml ) may occur when mitigating uncertainty is important . a research direction to study social networks for dealing with uncertainty then is posited .']"
400,information systems,conjunction,semantic web technologies,luanyi,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
401,ontologies,conjunction,semantic web technologies,luanyi,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
402,semantic web technologies,uses,technology,luanyi,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
403,knowledge management,uses,technology,luanyi,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
404,knowledge management,conjunction,semantic web technologies,luanyi,1,"[""steffen staab is professor for databases and information systems at the university of koblenz-landau , leading the research group on information systems and semantic web ( isweb ) . his interests lie in researching core technology for ontologies and semantic web as well as in applied research for exploiting these technologies for knowledge management , multimedia and software technology.he has participated in numerous national , european and intercontinental research projects on these different subjects and his research has led to more than 100 refereed contributions in journals and conferences . dr. staab held positions as researcher , project leader and lecturer at the university of freiburg , the university of stuttgart/fraunhofer institute iao , and the university of karlsruhe and he is a co-founder of ontoprise gmbh . he is on several journal editorial boards and is incoming editor-in-chief of elsevier 's journal of web semantics . for more information see : http : //isweb.unikoblenz . de/ and http : //www.uni-koblenz.de/ staab/""]"
405,reasoning algorithms,uses,"distributed , partially implicit assumption",luanyi,1,"['the semantic web is a powerful vision that is getting to grips with the challenge of providing more human-oriented web services . hence , reasoning with and across distributed , partially implicit assumptions ( contextual knowledge ) , is a milestone . ontologies are a primary means to deploy the semantic web vision , but few work has been done on them to manage the context-dependency of web knowledge . in this paper we introduce an ontology for representing a variety of reified contexts and states of affairs , called d & s , currently implemented as a plug-in to the dolce foundational ontology , and its application to two casts : an ontology for communication situations and roles , and an ontology for peer-to-peer communication . the reified contexts represented in d & s have a rich structure , and are a middleware between full-fledged formal contexts and theories , and the often poor vocabularies implemented in web ontologies ...']"
406,feature - based service model,uses,mass customization,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
407,semantic web technologies,uses,mass customization,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
408,service customization,uses,mass customization,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
409,service customization,uses,modularity of service product design,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
410,feature - based service model,uses,ontology - based service product modeling approach,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
411,semantic web technologies,uses,ontology - based service product modeling approach,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
412,service customization,uses,ontology - based service product modeling approach,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
413,semantic web technologies,uses,feature - based service model,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
414,service customization,uses,feature - based service model,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
415,semantic web technologies,uses,ontology language,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
416,semantic web technologies,uses,semantic web rule languages,luanyi,1,"['mass customization ( mc ) paradigm is getting crucial to service industry.this paper stated the mechanism of realization and key technology of mass customization in service product.considered modularity basic for service product family and platform.aiming to facilitate the sharing and reusing of the service product configuration model , based on the modularity of service product design , presented an ontology-based service product modeling approach for configuration.formalized the feature-based service model in owl ( ontology web language ) -an ontology language for semantic web , and formalized configuration rules in swrl ( semantic web rule language ) -a rule language.performed configuration reasoning processes with the support of jess ( java expert system shell ) rule engine.the proposed approach to service customization was demonstrated by an example of configuring service packages for china mobile.the approach is proved to be effective and easy to reuse and share , but how to optimize the configuration results is left to be studied later .']"
417,semantic web search engine,includes,conversation styled transcript,luanyi,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
418,semantic inference,uses,user query,luanyi,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
419,ontologies,conjunction,semantic web vocabulary,luanyi,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
420,semantic web vocabulary,conjunction,named entity extraction,luanyi,1,"['this paper describes the implementation of a semantic web search engine on conversation styled transcripts . our choice of data is hansard , a publicly available conversation style transcript of parliamentary debates . the current search engine implementation on hansard is limited to running search queries based on keywords or phrases hence lacks the ability to make semantic inferences from user queries . by making use of knowledge such as the relationship between members of parliament , constituencies , terms of office , as well as topics of debates the search results can be improved in terms of both relevance and coverage . our contribution is not algorithmic instead we describe how we exploit a collection of external data sources , ontologies , semantic web vocabularies and named entity extraction in the analysis of underlying semantics of user queries as well as the semantic enrichment of the search index thereby improving the quality of results .']"
